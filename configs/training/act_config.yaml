# ACT (Action Chunking Transformer) Training Configuration

# Dataset
dataset:
  repo_id: "your-username/robot-dataset"  # HuggingFace dataset repo
  local_path: null  # Optional: use local dataset
  train_split: 0.95  # 95% train, 5% validation

# Policy configuration
policy:
  type: "act"
  name: "act_policy"

  # ACT-specific parameters
  act:
    n_action_steps: 100  # Number of action predictions
    chunk_size: 100      # Action chunk size
    hidden_dim: 512
    n_encoder_layers: 4
    n_decoder_layers: 1
    n_heads: 8
    dropout: 0.1

  # Vision encoder
  vision:
    backbone: "resnet18"  # or "resnet34", "efficientnet"
    pretrained: true
    freeze_backbone: false

  # Input/output shapes (auto-detected from dataset if not specified)
  observation:
    state_dim: 6          # Joint positions
    image_size: [224, 224]
  action:
    action_dim: 6         # Target joint positions

# Training parameters
training:
  num_epochs: 5000
  batch_size: 8
  learning_rate: 1.0e-4
  weight_decay: 1.0e-4
  grad_clip: 10.0

  # Learning rate schedule
  lr_scheduler: "cosine"  # or "step", "exponential"
  lr_warmup_epochs: 100

  # Optimization
  optimizer: "adam"
  use_amp: false  # Automatic Mixed Precision

  # Device
  device: "cuda"  # or "cpu"
  num_workers: 4  # DataLoader workers

# Validation
validation:
  eval_freq: 100  # Evaluate every N epochs
  save_freq: 500  # Save checkpoint every N epochs
  num_eval_episodes: 10

# Logging
logging:
  log_freq: 10  # Log every N steps
  output_dir: "outputs/train/act_robot"

  # Weights & Biases
  wandb:
    enabled: false
    project: "robot-learning"
    entity: null
    name: null  # Auto-generated if null
    tags: ["act", "robot"]

# Checkpointing
checkpoint:
  save_best: true
  save_last: true
  monitor: "val_loss"  # Metric to monitor
  mode: "min"  # "min" or "max"

# Reproducibility
seed: 42
